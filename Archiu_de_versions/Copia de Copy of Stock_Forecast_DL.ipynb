{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PvpIKHaFSpDNnRUipg1rvbcNeZm-qBOg","timestamp":1717343255795}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Final Project**\n","\n","For our final project we try to forecast stock price on a given day from a sequence from previous days data.\n","\n","We will try several models, starting from a simple LSTM adapted from our Lab 2 work.  With some modifications:\n","\n","* Removing the last linear layer activation function as we are going to do a forecast and not a classification.\n","\n","* Reshaping the output dimensions so that we can predict as many features as we like.\n","\n","* Changing the loss function into a MSE lost.\n"],"metadata":{"id":"PJayRaSxnLX1"}},{"cell_type":"code","source":["from google.colab import drive\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from torch.nn.modules import activation\n","import torch\n","from torch import nn\n","import torch.optim as optim"],"metadata":{"id":"KcKG1NmNyRw8","executionInfo":{"status":"ok","timestamp":1717424085545,"user_tz":-120,"elapsed":7333,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","myDrive = '/content/drive/Shareddrives/Deep_Learning_2024/Final/Data/Mixed_ETF/'"],"metadata":{"id":"FzSofREfy0tD","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"error","timestamp":1717424207080,"user_tz":-120,"elapsed":121541,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}},"outputId":"48cd4116-ca18-49df-bda6-df05f2cc0fe7"},"execution_count":4,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-61fa6f2adfa9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmyDrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/Shareddrives/Deep_Learning_2024/Final/Data/Mixed_ETF/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         )\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}]},{"cell_type":"code","source":["file_path = os.path.join(myDrive,'ETF_Data.csv')\n","data = pd.read_csv(file_path, sep=\",\", header=0)"],"metadata":{"id":"McYV0EEDzpI0","executionInfo":{"status":"aborted","timestamp":1717424207081,"user_tz":-120,"elapsed":7,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Split Data"],"metadata":{"id":"iLpbwou86XcZ"}},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"IDLAFxtN6W5t","executionInfo":{"status":"aborted","timestamp":1717424207081,"user_tz":-120,"elapsed":7,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vaw'], label='vaw')\n","plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vcr'], label='vcr')\n","plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vht'], label='vht')\n","plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vgt'], label='vgt')\n","plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vfh'], label='vfh')\n","plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vde'], label='vde')\n","plt.plot(pd.to_datetime(data['Date_vaw']), data['Close_vnq'], label='vnq')\n","plt.xlabel('Date')\n","plt.ylabel('Close Value')\n","plt.title('Close values graph')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"x9DtB1W65t1e","executionInfo":{"status":"aborted","timestamp":1717424207082,"user_tz":-120,"elapsed":7,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.rename(columns={'Date_vaw': 'Date'}, inplace=True)\n","data.index = data['Date']\n","data.pop('Date')\n","Train = data[:2560]\n","Test = data[2560:]\n","print(Train.shape)\n","print(Test.shape)\n","print(len(Test))"],"metadata":{"id":"G2lnvTHU2C2m","executionInfo":{"status":"aborted","timestamp":1717424207082,"user_tz":-120,"elapsed":6,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mode_list = ['multi', 'single']\n","ETF = ['vaw', 'vcr', 'vgt', 'vfh', 'vde', ' vht', 'vnq']\n","mode = 'single'\n","ETF_active = ETF[0];"],"metadata":{"id":"Rbn5eS5ZoO-v","executionInfo":{"status":"aborted","timestamp":1717424207082,"user_tz":-120,"elapsed":6,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Convert DataFrame to numpy array\n","if (mode == mode_list[0]):\n","  Train_array = Train.to_numpy()\n","  Test_array = Test.to_numpy()\n","else:\n","  Train_array = Train[['Open_'  + ETF_active,'High_' + ETF_active,'Low_'  + ETF_active,'Close_'  + ETF_active,'Volume_'  + ETF_active]].to_numpy()\n","  Test_array = Test[['Open_'  + ETF_active,'High_' + ETF_active,'Low_'  + ETF_active,'Close_'  + ETF_active,'Volume_'  + ETF_active]].to_numpy()\n","\n","if (mode == mode_list[0]):\n","  Y_train = Train[['Close_vaw','Close_vcr','Close_vgt','Close_vfh','Close_vde','Close_vht','Close_vnq']].to_numpy()\n","  Y_test = Test[['Close_vaw','Close_vcr','Close_vgt','Close_vfh','Close_vde','Close_vht','Close_vnq']].to_numpy()\n","else:\n","  Y_train = Train[['Close_'  + ETF_active]].to_numpy()\n","  Y_test = Test[['Close_'  + ETF_active]].to_numpy()\n","\n","mean = np.mean(Train_array, axis=(0, 1))  # Mean for each feature across all samples and timesteps\n","std = np.std(Train_array, axis=(0, 1))  # Std for each feature across all samples and timesteps\n","# Prevent division by zero by replacing zero std with 1\n","std = np.where(std == 0, 1, std)\n","\n","# Normalize training data\n","Train_normalized = (Train_array - mean) / std\n","\n","# Normalize test data\n","Test_normalized = (Test_array - mean) / std\n","\n","mean_targets = np.mean(Y_train, axis=0)\n","std_targets = np.std(Y_train, axis=0)\n","std_targets[std_targets == 0] = 1  # Prevent division by zero\n","\n","Y_train_normalized = (Y_train - mean_targets) / std_targets\n","Y_test_normalized = (Y_test - mean_targets) / std_targets\n","\n","# Convert to PyTorch tensors\n","X_train_pt = torch.tensor(Train_normalized, dtype=torch.float32).cuda()\n","Y_train_pt = torch.tensor(Y_train_normalized, dtype=torch.float32).cuda()\n","X_test_pt = torch.tensor(Test_normalized, dtype=torch.float32).cuda()\n","Y_test_pt = torch.tensor(Y_test_normalized, dtype=torch.float32).cuda()\n","\n","print(\"Shapes of normalized training and test sets:\")\n","print(\"X_train_pt:\", X_train_pt.shape)\n","print(\"Y_train_pt:\", Y_train_pt.shape)\n","print(\"X_test_pt:\", X_test_pt.shape)\n","print(\"Y_test_pt:\", Y_test_pt.shape)"],"metadata":{"id":"ZPSk6LN53k2c","executionInfo":{"status":"aborted","timestamp":1717424207082,"user_tz":-120,"elapsed":5,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fragment_size = 10\n","step = 1\n","\n","if mode == mode_list[0]:\n","    Train_Fragmented = [Train_normalized[i:i + fragment_size] for i in range(0, len(Train_normalized) - fragment_size, step)]\n","    Train_Labels = [Train_normalized[i][['Close_vaw', 'Close_vcr', 'Close_vgt', 'Close_vfh', 'Close_vde', 'Close_vht', 'Close_vnq']] for i in range(fragment_size, len(Train_normalized), step)]\n","\n","    Test_Fragmented = [Test_normalized[i:i + fragment_size] for i in range(0, len(Test_normalized) - fragment_size, step)]\n","    Test_Labels = [Test_normalized[i][['Close_vaw', 'Close_vcr', 'Close_vgt', 'Close_vfh', 'Close_vde', 'Close_vht', 'Close_vnq']] for i in range(fragment_size, len(Test_normalized), step)]\n","else:\n","    # Assuming ETF_active is a string\n","    feature_columns = ['Open_' + ETF_active, 'High_' + ETF_active, 'Low_' + ETF_active, 'Close_' + ETF_active, 'Volume_' + ETF_active]\n","    Train_Fragmented = [Train_normalized[i:i + fragment_size][:, [Train.columns.get_loc(col) for col in feature_columns]] for i in range(0, len(Train_normalized) - fragment_size, step)]\n","    Train_Labels = [Train_normalized[i, Train.columns.get_loc('Close_' + ETF_active)] for i in range(fragment_size, len(Train_normalized), step)]\n","\n","    Test_Fragmented = [Test_normalized[i:i + fragment_size][:, [Test.columns.get_loc(col) for col in feature_columns]] for i in range(0, len(Test_normalized) - fragment_size, step)]\n","    Test_Labels = [Test_normalized[i, Test.columns.get_loc('Close_' + ETF_active)] for i in range(fragment_size, len(Test_normalized), step)]\n"],"metadata":{"id":"vCFTuRWbaq4e","executionInfo":{"status":"aborted","timestamp":1717424207083,"user_tz":-120,"elapsed":6,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''fragment_size = 10;\n","step = 1\n","\n","if (mode == mode_list[0]):\n","  Train_Fragmented = [Train_normalized.iloc[i:i + fragment_size] for i in range(0, len(Train_normalized) - fragment_size, step)]\n","  Train_Labels = [Train_normalized.iloc[i][['Close_vaw','Close_vcr','Close_vgt','Close_vfh','Close_vde','Close_vht','Close_vnq']] for i in range(fragment_size, len(Train_normalized), step)]\n","\n","  Test_Fragmented = [Test_normalized .iloc[i:i + fragment_size] for i in range(0, len(Test_normalized ) - fragment_size, step)]\n","  Test_Labels = [Test_normalized .iloc[i][['Close_vaw','Close_vcr','Close_vgt','Close_vfh','Close_vde','Close_vht','Close_vnq']] for i in range(fragment_size, len(Test_normalized ), step)]\n","else:\n","  Train_Fragmented = [Train_normalized.iloc[i:i + fragment_size][['Open_'  + ETF_active,'High_' + ETF_active,'Low_'  + ETF_active,'Close_'  + ETF_active,'Volume_'  + ETF_active]] for i in range(0, len(Train_normalized) - fragment_size, step)]\n","  Train_Labels = [Train_normalized.iloc[i][['Close_'  + ETF_active]] for i in range(fragment_size, len(Train_normalized), step)]\n","\n","  Test_Fragmented = [Test.iloc[i:i + fragment_size][['Open_'  + ETF_active,'High_' + ETF_active,'Low_'  + ETF_active,'Close_'  + ETF_active,'Volume_'  + ETF_active]] for i in range(0, len(Test_normalized ) - fragment_size, step)]\n","  Test_Labels = [Test.iloc[i][['Close_'  + ETF_active]] for i in range(fragment_size, len(Test_normalized ), step)]'''\n"],"metadata":{"id":"9y2RujbG7i5Z","executionInfo":{"status":"aborted","timestamp":1717424207083,"user_tz":-120,"elapsed":6,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print dimensions for verification\n","print(f'Number of Train Fragments: {len(Train_Fragmented)}')\n","print(f'Number of Train Labels: {len(Train_Labels)}')\n","print(f'Number of Test Fragments: {len(Test_Fragmented)}')\n","print(f'Number of Test Labels: {len(Test_Labels)}')\n"],"metadata":{"id":"K0ZCvAEqHYz6","executionInfo":{"status":"aborted","timestamp":1717424207083,"user_tz":-120,"elapsed":6,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print start and end of training and test data for verification\n","print(f'\\nTraining data\\n')\n","print(Train_Fragmented[1].columns.get_loc('Close_' + ETF_active))\n","print(Train_Labels[1])\n","print(Train_Fragmented[2].columns.get_loc('Close_' + ETF_active))\n","print(Train_Labels[2])\n","\n","print(Train_Fragmented[2548].columns.get_loc('Close_' + ETF_active))\n","print(Train_Labels[2548])\n","print(Train_Fragmented[2549].columns.get_loc('Close_' + ETF_active))\n","print(Train_Labels[2549])\n","\n","print(f'\\nTest data\\n')\n","print(Test_Fragmented[0].columns.get_loc('Close_' + ETF_active))\n","print(Test_Labels[0])\n","print(Test_Fragmented[1].columns.get_loc('Close_' + ETF_active))\n","print(Test_Labels[1])\n","\n","print(Test_Fragmented[629].columns.get_loc('Close_' + ETF_active))\n","print(Test_Labels[629])\n","print(Test_Fragmented[630].columns.get_loc('Close_' + ETF_active))\n","print(Test_Labels[630])"],"metadata":{"id":"Bhc3L2wtbkWW","executionInfo":{"status":"aborted","timestamp":1717424207084,"user_tz":-120,"elapsed":6,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''#Print start and end of training and test data for verification\n","print(f'\\nTraining data\\n')\n","print(Train_Fragmented[1]['Close_' + ETF_active])\n","print(Train_Labels[1])\n","print(Train_Fragmented[2]['Close_' + ETF_active])\n","print(Train_Labels[2])\n","\n","print(Train_Fragmented[2548]['Close_' + ETF_active])\n","print(Train_Labels[2548])\n","print(Train_Fragmented[2549]['Close_' + ETF_active])\n","print(Train_Labels[2549])\n","\n","print(f'\\nTest data\\n')\n","print(Test_Fragmented[0]['Close_' + ETF_active])\n","print(Test_Labels[0])\n","print(Test_Fragmented[1]['Close_' + ETF_active])\n","print(Test_Labels[1])\n","\n","print(Test_Fragmented[629]['Close_' + ETF_active])\n","print(Test_Labels[629])\n","print(Test_Fragmented[630]['Close_' + ETF_active])\n","print(Test_Labels[630])'''"],"metadata":{"id":"saTajud840tE","executionInfo":{"status":"aborted","timestamp":1717424207084,"user_tz":-120,"elapsed":129198,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Test_Fragmented[5]['Close_' + ETF_active])\n","print(Test_Fragmented[6]['Close_' + ETF_active])\n","# Plot the time series data using Matplotlib\n","plt.figure(figsize=(10, 6))\n","plt.plot(Test_Fragmented[5].index, Test_Fragmented[5]['Close_' + ETF_active], label='Close_'  + ETF_active + '_frag5')\n","plt.plot(Test_Fragmented[6].index, Test_Fragmented[6]['Close_' + ETF_active], label='Close_'  + ETF_active + '_frag6')\n","plt.xlabel('Date')\n","plt.ylabel('Value')\n","plt.title('Time Series Plot')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"heGFQplaBnRh","executionInfo":{"status":"aborted","timestamp":1717424207084,"user_tz":-120,"elapsed":129197,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2MG3HI1nKLQ","executionInfo":{"status":"aborted","timestamp":1717424207085,"user_tz":-120,"elapsed":129197,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"outputs":[],"source":["# Define module encapsulating a Sequence Classifier using RNN or LSTMs and setting different architecture hyper-parameters\n","class Simple_LSTM(nn.Module):\n","  def __init__(self,\n","               input_size : int = 5,\n","               hidden_size : int = 64,\n","               output_size : int = 1,\n","               num_layers : int =  5,\n","               activation_function = nn.Softmax(dim = 1)):  #softmax activation function in order to get multiclass probability\n","    # Define RNN or LSTM architecture\n","    super().__init__()\n","    self.rnn =  nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n","                          num_layers=num_layers, batch_first = True)\n","\n","    self.activation_function = activation_function\n","\n","    self.last_linear = nn.Linear(hidden_size,output_size)\n","\n","  def forward(self, X):\n","    _,last_states = self.rnn(X)\n","    # Get last hidden state for last layer. Ignore cell state in case of LSTMs\n","    last_hidden_state = last_states[0][-1, :, :]\n","    # Get sequence label probability using the last hidden state\n","    next_prediction = self.last_linear(last_hidden_state)\n","    return next_prediction\n"]},{"cell_type":"code","source":["def train_simple_LSTM(X_train, Y_train, model, optimizer, loss_func, epochs=100):\n","    loss_its = []\n","    for iter in range(epochs):\n","      optimizer.zero_grad()\n","      output = model(X_train)\n","      loss = loss_func(output,Y_train)\n","      loss_its.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","    print(f'Final loss: {loss.item()}')\n","    return np.asarray(loss_its)"],"metadata":{"id":"7aOViQG1rUtd","executionInfo":{"status":"aborted","timestamp":1717424207085,"user_tz":-120,"elapsed":129196,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensor_list = [torch.tensor(fragment.values, dtype=torch.float32) for fragment in Train_Fragmented]\n","X_train = torch.stack(tensor_list)\n","label_tensor_list = [torch.tensor(fragment.values, dtype=torch.float32) for fragment in Train_Labels]\n","Y_train =  torch.stack(label_tensor_list)\n","\n","tensor_list_test = [torch.tensor(fragment.values, dtype=torch.float32) for fragment in Test_Fragmented]\n","X_test = torch.stack(tensor_list_test)\n","label_tensor_list_test = [torch.tensor(fragment.values, dtype=torch.float32) for fragment in Test_Labels]\n","Y_test =  torch.stack(label_tensor_list_test)"],"metadata":{"id":"svQxJZdRX8lo","executionInfo":{"status":"aborted","timestamp":1717424207085,"user_tz":-120,"elapsed":129195,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_pt = X_train.float().cuda()\n","Y_train_pt = Y_train.float().cuda()\n","X_test_pt = X_test.float().cuda()\n","Y_test_pt = Y_test.float().cuda()\n","\n","print(X_train.shape)\n","print(Y_train.shape)"],"metadata":{"id":"QSg49PbmnZU_","executionInfo":{"status":"aborted","timestamp":1717424207085,"user_tz":-120,"elapsed":129195,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''if (mode == mode_list[0]):\n","  input_size = 35\n","  hidden_size = 256\n","  num_layers = 2\n","  output_size = 7\n","  num_epochs = 4000\n","else:\n","  input_size = 5\n","  hidden_size = 256\n","  num_layers = 2\n","  output_size = 1\n","  num_epochs = 4000\n","\n","# Define model, loss function, and optimizer\n","model = Simple_LSTM(input_size=input_size, hidden_size=hidden_size, output_size = output_size, num_layers=num_layers).cuda()\n","loss_func = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","loss_history = train_simple_LSTM(X_train_pt, Y_train_pt, model, optimizer, loss_func, epochs=num_epochs)'''"],"metadata":{"id":"j5cO638gwG8m","executionInfo":{"status":"aborted","timestamp":1717424207085,"user_tz":-120,"elapsed":129194,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if (mode == mode_list[0]):\n","  input_size = 35\n","  hidden_size = 256\n","  num_layers = 2\n","  output_size = 7\n","  num_epochs = 400\n","else:\n","  input_size = 5\n","  hidden_size = 64\n","  num_layers = 2\n","  output_size = 1\n","  num_epochs = 400\n","\n","# Define model, loss function, and optimizer\n","model = Simple_LSTM(input_size=input_size, hidden_size=hidden_size, output_size = output_size, num_layers=num_layers).cuda()\n","loss_func = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","loss_its = []\n","for iter in range(num_epochs):\n","  optimizer.zero_grad()\n","  output = model(X_train_pt)\n","  loss = loss_func(output,Y_train_pt)\n","  loss_its.append(loss.item())\n","  loss.backward()\n","  optimizer.step()\n","\n","  if( iter%50 == 0):\n","    print(f'Final loss: {loss.item()}')\n","\n","#loss_history = train_simple_LSTM(X_train_pt, Y_train_pt, model, optimizer, loss_func, epochs=num_epochs)\n"],"metadata":{"id":"ZdO7KQmSvB9v","executionInfo":{"status":"aborted","timestamp":1717424207086,"user_tz":-120,"elapsed":129195,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Histogram"],"metadata":{"id":"6pCKbL03Sl7V"}},{"cell_type":"code","source":["Y_predicted = model(X_test_pt).cpu().detach().numpy()\n","Y = Y_test_normalized.to_numpy()\n","print(Y_predicted)"],"metadata":{"id":"VXkfKBXeHqxr","executionInfo":{"status":"aborted","timestamp":1717424207086,"user_tz":-120,"elapsed":129194,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = os.path.join(myDrive,'Y_predicted.csv')\n","pd.DataFrame(Y_predicted).to_csv(file_path, index=False)"],"metadata":{"id":"XO5zIkadaXl3","executionInfo":{"status":"aborted","timestamp":1717424207086,"user_tz":-120,"elapsed":129193,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Example arrays for Y_predicted and Y\n","# Ensure these are defined as per your actual data\n","# Y_predicted = np.random.randn(640, 6)  # Example: If Y_predicted is a 2D array\n","# Y = np.random.randn(640, 6, 1)  # Example: If Y is a 3D array\n","\n","# Ensure `Y` is 2D by squeezing the last dimension\n","Y_squeezed = Y.squeeze()\n","\n","# Check the shapes (for debugging purposes)\n","print(\"Y_predicted shape:\", Y_predicted.shape)\n","print(\"Y shape after squeezing:\", Y_squeezed.shape)\n","\n","# Plot the actual signals\n","plt.figure(figsize=(12, 8))\n","if Y_squeezed.ndim == 2:\n","  for i in range(Y_squeezed.shape[1]):\n","      plt.plot(Y_squeezed[:, i], label=f\"Actual Signal {i+1}\")\n","else:\n","  plt.plot(Y_squeezed[:], label=f\"Actual Signal {1}\")\n","\n","# Ensure Y_predicted is compatible for plotting\n","if Y_predicted.shape[1] == 1:\n","    # If Y_predicted is 1D, we plot it directly\n","    plt.plot(Y_predicted, label=\"Predicted Signal\", linestyle='--')\n","elif Y_predicted.ndim == 2 and Y_predicted.shape[1] == Y_squeezed.shape[1]:\n","    # If Y_predicted is 2D, plot each predicted signal\n","    for i in range(Y_predicted.shape[1]):\n","        plt.plot(Y_predicted[:, i], linestyle='--', label=f\"Predicted Signal {i+1}\")\n","\n","plt.title('Overlayed 6 Signals with 256 Samples Each')\n","plt.xlabel('Sample Index')\n","plt.ylabel('Value')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"KcWAlRpByUjF","executionInfo":{"status":"aborted","timestamp":1717424207086,"user_tz":-120,"elapsed":129193,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 8))\n","plt.plot(Y_predicted)\n","plt.plot(Y)\n","plt.title('Overlayed 6 Signals with 256 Samples Each')\n","plt.xlabel('Sample Index')\n","plt.ylabel('Signal Value')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"uQU4WLwkUjWl","executionInfo":{"status":"aborted","timestamp":1717424207087,"user_tz":-120,"elapsed":129193,"user":{"displayName":"PAU AMETLLER LÓPEZ","userId":"10993844144958153651"}}},"execution_count":null,"outputs":[]}]}